<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.1 Basic Terminology | Predictive Analytics</title>
  <meta name="description" content="A guide to the theory of predictive analytics." />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="1.1 Basic Terminology | Predictive Analytics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="A guide to the theory of predictive analytics." />
  <meta name="github-repo" content="jeffamaxey/predictive-analytics" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.1 Basic Terminology | Predictive Analytics" />
  
  <meta name="twitter:description" content="A guide to the theory of predictive analytics." />
  

<meta name="author" content="Jeff Maxey" />


<meta name="date" content="2025-03-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>
<link rel="next" href="the-model-building-process.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Theory of Predictive Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="why-read-this-book.html"><a href="why-read-this-book.html"><i class="fa fa-check"></i>Why read this book</a></li>
<li class="chapter" data-level="" data-path="structure-of-the-book.html"><a href="structure-of-the-book.html"><i class="fa fa-check"></i>Structure of the book</a></li>
<li class="chapter" data-level="" data-path="software-information-and-conventions.html"><a href="software-information-and-conventions.html"><i class="fa fa-check"></i>Software information and conventions</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="part"><span><b>I Introduction to Predictive Analytics</b></span></li>
<li class="chapter" data-level="1" data-path="overview-of-predictive-analytics.html"><a href="overview-of-predictive-analytics.html"><i class="fa fa-check"></i><b>1</b> Overview of Predictive Analytics</a>
<ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1.1" data-path="basic-terminology.html"><a href="basic-terminology.html"><i class="fa fa-check"></i><b>1.1</b> Basic Terminology</a></li>
<li class="chapter" data-level="1.2" data-path="the-model-building-process.html"><a href="the-model-building-process.html"><i class="fa fa-check"></i><b>1.2</b> The Model Building Process</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="the-model-building-process.html"><a href="the-model-building-process.html#exam-note"><i class="fa fa-check"></i><b>1.2.1</b> ⚠ EXAM NOTE ⚠</a></li>
<li class="chapter" data-level="1.2.2" data-path="the-model-building-process.html"><a href="the-model-building-process.html#stage-1-problem-definition"><i class="fa fa-check"></i><b>1.2.2</b> Stage 1: Problem Definition</a></li>
<li class="chapter" data-level="1.2.3" data-path="the-model-building-process.html"><a href="the-model-building-process.html#problem-definition"><i class="fa fa-check"></i><b>1.2.3</b> Problem Definition</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="constraints.html"><a href="constraints.html"><i class="fa fa-check"></i><b>1.3</b> Constraints</a></li>
<li class="chapter" data-level="1.4" data-path="bias-variance-trade-off.html"><a href="bias-variance-trade-off.html"><i class="fa fa-check"></i><b>1.4</b> Bias-Variance Trade-off</a></li>
<li class="chapter" data-level="1.5" data-path="feature-generation-and-selection.html"><a href="feature-generation-and-selection.html"><i class="fa fa-check"></i><b>1.5</b> Feature Generation and Selection</a></li>
<li class="chapter" data-level="1.6" data-path="conceptual-review-questions-for-chapter-1.html"><a href="conceptual-review-questions-for-chapter-1.html"><i class="fa fa-check"></i><b>1.6</b> Conceptual Review Questions for Chapter 1</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-exploration-and-visualization.html"><a href="data-exploration-and-visualization.html"><i class="fa fa-check"></i><b>2</b> Data Exploration and Visualization</a>
<ul>
<li class="chapter" data-level="2.1" data-path="univariate-data-exploration.html"><a href="univariate-data-exploration.html"><i class="fa fa-check"></i><b>2.1</b> Univariate Data Exploration</a></li>
<li class="chapter" data-level="2.2" data-path="bivariate-data-exploration.html"><a href="bivariate-data-exploration.html"><i class="fa fa-check"></i><b>2.2</b> Bivariate Data Exploration</a></li>
<li class="chapter" data-level="2.3" data-path="conceptual-review-questions-for-chapter-2.html"><a href="conceptual-review-questions-for-chapter-2.html"><i class="fa fa-check"></i><b>2.3</b> Conceptual Review Questions for Chapter 2</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/jeffamaxey/predictive-analytics" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="basic-terminology" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Basic Terminology<a href="basic-terminology.html#basic-terminology" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Predictive Analytics in a nutshell.</strong> Three main categories of predictive
analytics problems:</p>
<ul>
<li><p><strong><em>Descriptive:</em></strong> Focuses on what happened in the past and aims to
“describe” or explain the observed patterns by identifying the relationships
between different variables in the data.</p>
<p><strong>Example.</strong> If you saw an increase in the lapse rate among the
policyholders of a certain line of business, what kind of policyholders had
the highest tendency to lapse? What are their key characteristics? This is a
question addressed by descriptive analytics.</p></li>
<li><p><strong><em>Predictive:</em></strong> Focuses on what will happen in the <em>future</em> and is
concerned with making accurate “predictions”.</p>
<p><strong>Example:</strong> For a prospective policyholder with certain characteristics,
what is their predicted probability of lapse? The ability to make such a
prediction will be useful for identifying future policyholders who will have
a lower probability of lapse and contribute to the profitability of an
insurer.</p></li>
<li><p><strong><em>Prescriptive:</em></strong> Uses a combination of optimization and simulation to
quantify the impact of different “prescribed” actions in different
scenarios.</p>
<p><strong>Example:</strong> If we reduce the premium by a certain amount, how will this
affect the lapse rate? More generally, what is the best course of action to
reduce the lapse rate? Prescriptive analytics may give us some useful
insight.</p></li>
</ul>
<p>All predictive problems have something in common. There is always an output (or
outcome) of interest, which can be numeric (salary, premium) or categorical
(positive/negative, email/spam), and we have at our disposal a collection of
input variables that may offer potentially useful information for predicting or
understanding the output.</p>
<p>This “input-output” setting, depicted below, is characteristic of predictive
analytics in general, and our job is to develop a model teasing the (possibly
complex, overlapping) contributions of the inputs to the output.</p>
<p><span class="math display">\[
\underset{\underset{Output}{\text{Target Variable}}}{Y} \overset{\text{Predict}}{\underset{\text{}}{\dashleftarrow}}\underset{\underset{Inputs}{\text{Predictors}}}{X = (X_1,...,Xp)}
\]</span></p>
<hr />
<p><strong>Classification of Variables.</strong> Predictive analytics requires data, often with
a large number of observations and variables. In Exam PA, we will be mostly
dealing with datasets that can be displayed in the following
observation-by-variable rectangular array format (such data is called
<strong><em>structured data</em></strong> and is stored in <code>R</code> in a data frame).</p>
<table>
<caption><strong>TABLE 1:</strong> Structured Data Format</caption>
<colgroup>
<col width="24%" />
<col width="17%" />
<col width="23%" />
<col width="12%" />
<col width="8%" />
<col width="12%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong><em>Observation</em></strong></th>
<th align="center"><strong><em>Target</em></strong></th>
<th align="center"><strong><em>Predictors</em></strong></th>
<th align="center"></th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"></td>
<td align="center"><span class="math inline">\(Y\)</span></td>
<td align="center"><span class="math inline">\(X_1\)</span></td>
<td align="center"><span class="math inline">\(X_2\)</span></td>
<td align="center"><span class="math inline">\(...\)</span></td>
<td align="center"><span class="math inline">\(X_p\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(1\)</span></td>
<td align="center"><span class="math inline">\(Y_1\)</span></td>
<td align="center"><span class="math inline">\(X_{11}\)</span></td>
<td align="center"><span class="math inline">\(X_{12}\)</span></td>
<td align="center"><span class="math inline">\(...\)</span></td>
<td align="center"><span class="math inline">\(X_{1p}\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(2\)</span></td>
<td align="center"><span class="math inline">\(Y_2\)</span></td>
<td align="center"><span class="math inline">\(X_{21}\)</span></td>
<td align="center"><span class="math inline">\(X_{22}\)</span></td>
<td align="center"><span class="math inline">\(...\)</span></td>
<td align="center"><span class="math inline">\(X_{2p}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(...\)</span></td>
<td align="center"><span class="math inline">\(...\)</span></td>
<td align="center"><span class="math inline">\(...\)</span></td>
<td align="center"><span class="math inline">\(...\)</span></td>
<td align="center"><span class="math inline">\(...\)</span></td>
<td align="center"><span class="math inline">\(...\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(n\)</span></td>
<td align="center"><span class="math inline">\(Y_n\)</span></td>
<td align="center"><span class="math inline">\(X_{n1}\)</span></td>
<td align="center"><span class="math inline">\(X_{n2}\)</span></td>
<td align="center"><span class="math inline">\(...\)</span></td>
<td align="center"><span class="math inline">\(X_{np}\)</span></td>
</tr>
</tbody>
</table>
<p>In the dataset above, the <em>observations</em> are shown across the rows of the array
(from 1 to <span class="math inline">\(n\)</span>) and the corresponding <em>variable</em> values are shown in the
columns. Each observation comprises measurements taken for multiple variables,
so, for example, the first observation of the data consists of:</p>
<p><span class="math display">\[
Y_1,X_{11},X_{12},...,X_{1p},
\]</span></p>
<p>not just <span class="math inline">\(Y_1\)</span> or <span class="math inline">\(X_{11},X_{12},...,X_{1p}\)</span>. In the actuarial salary example
above, you can think of each observation as an actuary you are able to sample,
and the variables represent the characteristics of that actuary.</p>
<p>Generally speaking, there are two ways to classify variables in a predictive
analytics context: By their role in the study (intended use) or by their nature
(characteristics).</p>
<ul>
<li><p><strong>By Role: Target vs. Predictors</strong></p>
<p>In the dataset above, we refer to the variable that we are interested in as
the <strong><em>target variable</em></strong>, or simply the <strong><em>target</em></strong> (a.k.a <strong><em>response
variable</em></strong>, <strong><em>dependent variable</em></strong>, <em><strong>output variable</strong>, <strong>outcome
variable</strong>),</em> and denote it by <span class="math inline">\(\bf{Y}\)</span>.</p>
<p>Despite the target variable being our prime interest, in most situations we
cannot change the target directly, but we have more direct control over some
associated variables which may offer explanatory information about the
target. These variables go by different names, such as <strong><em>predictors</em></strong>,
<strong><em>explanatory variables, independent variables, input variables,</em></strong> or
sometimes simply <strong><em>variables</em></strong> if no confusion arises, and we denote them
by <span class="math inline">\(\bf{X_1, X_2, ..., X_p}\)</span>. In an actuarial context, predictors are also
known as risk factors or risk drivers. In the rest of this manual, we will
mostly use the term “predictors” and “features”.</p>
<p>Throughout the study of predictive analytics, it is useful to think of a
predictive model as the following functional relationship between the target
variable <span class="math inline">\(\bf{Y}\)</span> and the corresponding set of <span class="math inline">\(\bf{p}\)</span> predictors
<span class="math inline">\(\bf{X=(X_1,...,X_p)}\)</span> (collected as a vector):</p>
<p><span class="math display" id="eq:modelformula">\[
\begin{equation}
Y_i=f\left(X_i\right)+\epsilon_i, i=1,...,n
\tag{1.1}
\end{equation}
\]</span></p>
<p>where:</p>
<ul>
<li>The subscript <span class="math inline">\(i\)</span> signifies the <span class="math inline">\(i\)</span>-th observation in the dataset, so
<span class="math inline">\(Y_i\)</span> is the value of the target variable for the <span class="math inline">\(i\)</span>-th observation and
<span class="math inline">\(X_i = (X_{i1}, ..., X_{ip})\)</span> is the corresponding vector of predictor
values.</li>
<li><span class="math inline">\(f\)</span> is a fixed (non-random) but unknown function corresponding the
predictors and the target variable.
<ul>
<li>Without the subscript <span class="math inline">\(i\)</span> (note that is <span class="math inline">\(f\)</span> rather than <span class="math inline">\(f_i\)</span>), the
function applies to all observations in the data, and forms the
“systematic” part of <a href="basic-terminology.html#eq:modelformula">(1.1)</a>.</li>
<li>Largely synonymous with the model, this function carries the
systematic information that the predictors offer about the target
variable, and allows us to differentiate, or discriminate, the
observations of the target variable on the basis of those
predictors.</li>
</ul></li>
<li><span class="math inline">\(\epsilon_i\)</span> is a zero-mean random error term carrying information that
is specific to the <span class="math inline">\(i\)</span>-th observation, hence “idiosyncratic” and the
presence of the subscript <span class="math inline">\(i\)</span>.
<ul>
<li>It can be regarded as the catch-all for what the systematic
component of the model misses, e.g., the true relationship between
<span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is probably more complex than <a href="basic-terminology.html#eq:modelformula">(1.1)</a>,
there are other variables associated with <span class="math inline">\(Y\)</span> omitted by the model.</li>
</ul></li>
</ul>
<p>Although <a href="basic-terminology.html#eq:modelformula">(1.1)</a> looks abstract and the exam will not test it
directly, it will provide a useful framework for thinking about predictive
analytics. For convenience, we will refer to <span class="math inline">\(f\)</span> and <span class="math inline">\(\epsilon_i\)</span>
respectively as the signal function and the noise, which are widely used
terms originally stemming from engineering.</p>
<dl>
<dt>Goal of Predictive Analytics</dt>
<dd>
<p>We are interested in the signal, but the data we have is “contaminated”
with noise.</p>
<p>The goal of predictive analytics is to filter out the noise and use a
variety of tools and techniques to learn as much and as accurately about
the signal as possible from the data.</p>
<p>The knowledge about the signal can then provide us with a basis for
understanding the data-generating process underlying the population of
interest and making predictions for the target variable.</p>
</dd>
</dl></li>
<li><p><strong>By Nature: Numeric vs. Categorical</strong></p>
<p>Variables can also be classified as <strong><em>numeric</em></strong> variables or
<strong><em>categorical</em></strong> variables. Such a classification has important
implications for developing an effective predictive model that aligns with
the characteristics of the target variable and predictors to produce
realistic output.</p>
<ul>
<li><strong>Numeric (Quantitative) Variables:</strong> Numeric values that can take the
form of numbers with a well-defined order and an associated range.
<ul>
<li><strong>Discrete:</strong> Restricted to only certain numeric values in that
range, e.g., non-negative numbers.</li>
<li><strong>Continuous:</strong> Can assume any numeric value within the range of the
variable, at least in theory.</li>
</ul></li>
<li><strong>Categorical (Qualitative/Factor) Variables:</strong> Takes predefined values
in a countable collection of “categories”, also called the <strong><em>levels</em></strong>
or <strong><em>classes</em></strong> of the variable.
<ul>
<li><strong>Nominal:</strong>Levels have no numeric order, i.e., we cannot say which
category is larger or smaller.
<ul>
<li><strong>Examples:</strong> Smoking Status, Gender, Marital Status</li>
</ul></li>
<li><strong>Ordinal:</strong> Levels have a natural order.
<ul>
<li><strong>Examples:</strong> Health Status (Poor, Moderate, Good), Risk Group
(Preferred, Standard, Rated, Uninsurable).</li>
</ul></li>
</ul></li>
</ul>
<p></p>
<div class="rmdnote">
<p>In predictive modeling, the type of model to use is largely determined by the the nature of the target variable, not the predictors.</p>
<p>In other words, the distinction between numeric and categorical variables is relatively unimportant when they serve as predictors of a model, but we do need to take the distinction properly into account when they serve as the target variable.</p>
Some predictive models (e.g., linear models) work well only for numeric target variables while some (e.g., GLMs and decision trees) apply to both numeric and categorical target variables.
</div></li>
</ul>
<hr />
<p><strong>Supervised vs. Unsupervised Problems.</strong> Given the notions of target vs.
predictor variables and numeric vs. categorical variables, we can further
classify predictive analytics problems. Depending on the presence of a target
variable and the objective of analysis, we can describe them as <strong><em>supervised</em></strong>
or <strong><em>unsupervised learning</em></strong>.</p>
<ul>
<li><strong>Supervised Learning:</strong> Refers to those for which there is a target
variable “supervising” or guiding the analysis, and our goal is to
understand the relationship between the target and the predictors, and/or
make accurate predictions for the target based on the predictors.
<ul>
<li><div>
<div class="line-block"><strong>Models:</strong> GLMs (including linear models) and Decision Trees</div>
</div></li>
</ul></li>
<li><strong>Unsupervised Learning:</strong> For unsupervised learning methods, there is no
target variable supervising our analysis, and we are interested in
extracting relationships and structures between different variables in the
data.
<ul>
<li><div>
<div class="line-block"><strong>Models:</strong> Principal Components Analysis (PCA) and Cluster Analysis</div>
</div></li>
</ul></li>
</ul>
<hr />
<p><strong>Regression vs. Classification Problems.</strong> Finally, it is customary to refer to
supervised learning problems with a numeric target variable as <strong><em>regression
problems</em></strong> (an exception is logistic regression, for which the target variable
is binary). In contrast, when the target variable is categorical in nature, we
are dealing with <strong><em>classification problems</em></strong>. A predictive model for
predicting a categorical target involves “classifying” its observations to a
certain level and is aptly called a <em>classifier</em>.</p>
<p>Both regression and classification problems are of importance in Exam PA and
predictive modeling in general. The two kinds of predictive analytics problems
have their unique features and will be covered in detail in Part II of this
manual.</p>
<hr />
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="the-model-building-process.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": true,
    "facebook": false,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/jeffamaxey/predictive-analytics/edit/main/01-overview-of-predictive-analytics.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": "https://github.com/jeffamaxey/predictive-analytics/blob/main/01-overview-of-predictive-analytics.Rmd",
    "text": null
  },
  "download": ["bookdownproj.pdf", "bookdownproj.epub", "bookdownproj.mobi"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
